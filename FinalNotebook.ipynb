{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors:\n",
    "Aiden Smith (2173104), https://www.kaggle.com/aidenysmith27\n",
    "\n",
    "Benjamin Palay (1815593), https://www.kaggle.com/benpalayy\n",
    "\n",
    "Gia Croock (2128541), https://www.kaggle.com/giacroock\n",
    "\n",
    "Rael Ware (2153459), https://www.kaggle.com/raelware\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The titanic is known as one of the most infamous shipwrecks in history. Of the 2240 passengers aboard the ship, at least 1500 died. Using artificial intelligence, or more specifically, machine learning, the objective of this project is to classify the passengers on the Titanic into two labels, namely survivors and non-survivors, based on other known features. The project is taken from Kaggle’s competition called “Titanic: Machine Learning from Disaster.” Provided is a training dataset as well as a testing dataset. In the former, the passengers are already classified into the above two labels. \n",
    "\n",
    "\n",
    "Success criteria include achieving a score of above 75% on the Kaggle submission portal, as well as correctly tuning several machine learning algorithms to improve their accuracies. The algorothms that are tuned are Multi-Layer Perceptron, Logistic Regression, K-Nearest Neighbours and Random Forest. The performance of each algorithm was measured using K-Fold cross-validation. The constraints consist of writing strictly in python in a ipynb file, as well as having to implement at least two specific machine learning algorithms. The Notebook consists of library and data importing, data description, data analysis, data pre-processing (including transformation, removal of outliers, dealing with null and missing values,feature enginnering and feature encoding), modelling (including intermediate results), references, recommendations for improvement, a conclusion and an Appendix. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Data visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as pl\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# Tuning\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import and read data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The data provided is split into two groups:\n",
    "1) The training set (train.csv)\n",
    "2) The testing set (test.csv)\n",
    "\n",
    "The training set includes a survival column which indicates whether or not the passenger survived. This data set is used to create the machine learning model.\n",
    "The testing set is used to determine how well the model (generated from the training data set) performs on new unseen data. The testing data set does not provide the passengers' survival status. The model generated predicts the passengers' survival status.\n",
    "\n",
    "The table below provides all the relevant information about the columns in the data sets:\n",
    "\n",
    "| Column Name          | Description                                                | Key                    |\n",
    "| ---------------------| ---------------------------------------------------------- | ---------------------- |\n",
    "| __PassengerId__      | Passenger Identity                                         |                        | \n",
    "| __Survived__         | Passenger survival status                                  | 0 = No, 1 = Yes        | \n",
    "| __Pclass__           | Ticket class, a representation of socio-economic status (SES)| 1 = 1st class, 2 = 2nd class, 3 = 3rd class | \n",
    "| __Name__             | Passenger's name                                           |                        | \n",
    "| __Sex__              | Passenger's sex                                            |                        |\n",
    "| __Age__              | Passengers age (in years)                                  |                        |\n",
    "| __SibSp__            | Number of sibling and/or spouse travelling with passenger  |                        |\n",
    "| __Parch__            | Number of parent and/or children travelling with passenger |                        |\n",
    "| __Ticket__           | Ticket number                                              |                        |\n",
    "| __Fare__             | Price of the ticket                                        |                        |\n",
    "| __Cabin__            | Cabin number                                               |                        |\n",
    "| __Embarked__         | Point of embarkation                                       | C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "More information can be found under the [data](https://www.kaggle.com/c/titanic/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Exploratory data analysis is used to gain insight on the data provided. This is achieved by using visualisation tools such as graphs and tables. It will allow us to understand the data and derive preliminary conclusions. Furthermore, it will summerise important trends, characteristics, and abnormalities in the dataset which will ultimately aid in training the model.\n",
    "\n",
    "The following is explored and analysed:\n",
    "- Data Types\n",
    "- The shape of the data\n",
    "- Missing values in the data\n",
    "- Statistics derived from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Data types,data shapes, missing data and summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1.Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-null count and data types of the training\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='pink'>Observation:</font>  The training-set has 891 rows and 11 features including the __target variable (survived).__ 2 of the features are floats, 5 are integers and 5 are objects. When training, the model requires the data to all be in the form of numbers, therefore these columns will be converted later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2.Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of the training data set: \", train.shape)\n",
    "print(\"The shape of the testing data set: \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font> The testing data set has one column less column than the training data set (the Survived column). As discussed above in section 3, survived is our response/target variable and will therefore be determined from the model derived from the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3.Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Determine what percentage of data is missing values in each column of the training dataset\n",
    "totalNumberOfDataPoints = train.isnull().sum().sort_values(ascending=False)\n",
    "percentMissing = train.isnull().sum()/train.isnull().count()*100\n",
    "percentMissingRounded = (round(percentMissing, 1)).sort_values(ascending=False)\n",
    "missingData = pd.concat([totalNumberOfDataPoints, percentMissingRounded], axis=1, keys=['Total missing', '%'])\n",
    "missingData.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine what percentage of data is missing values in each column of the testing dataset\n",
    "totalNumberOfDataPoints = test.isnull().sum().sort_values(ascending=False)\n",
    "percentMissing = test.isnull().sum()/test.isnull().count()*100\n",
    "percentMissingRounded = (round(percentMissing, 1)).sort_values(ascending=False)\n",
    "missingData = pd.concat([totalNumberOfDataPoints, percentMissingRounded], axis=1, keys=['Total missing', '%'])\n",
    "missingData.head(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font> From the two tables above it can be seen that the training set has missing values in the Cabin, Age and Embarked columns. The testing dataset has missing values in the Cabin, Age and Fare columns. \n",
    "For the training dataset, the Embarked column only contains two missing values which can be easily dropped or filled. The Age column on the other hand has 177 missing values. We therefore, cannot drop the rows which have missing values in the age column as this will eliminate 20% of the training data. Therefore, these values need to be filled in. The approach taken to fill in the missing values is discussed below in section 5.2. Since the Cabin column is missing 77% of data points, we have decided to drop this column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4.Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the statistics for the training data set \n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The table above gives an overview of the central tendencies of the numeric data in the testing dataset. <br /> <font color='pink'>Observations:</font> \n",
    "- 38% of people in the training dataset survived the Titanic \n",
    "- The passenger age ranges from 0.4 to 80 years old.\n",
    "- There is an outlier in the Fare column because of the differences between the 75th percentile, standard deviation, and the max value (512). We will thus determine how to deal with this outlier by either dropping its corresponding row or filling the outlier with an appropriate value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For feature analysis the training dataset will be split into two categories:\n",
    "1) Categorical variables\n",
    "2) Numerical variables\n",
    "\n",
    "Categorical variables have values belonging to one of two or more categories. Numerical variables have a continuous distribution.\n",
    "Identifying which variables are categorical and which variables are numerical will hel structure the data analysis properly. For example it makes no sense to determine the average of a categorical variable such as sex or class. Furthermore, sex, class and embarked have no intrinsic ordering to its value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this data set the categorical variables are:\n",
    "1) Sex\n",
    "2) Pclass \n",
    "3) Embarked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1.1.Categorical variable: Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts of the sex column\n",
    "train['Sex'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font> There are 263 more male passengers than female passengers in the training dataset. Therefore there it is assumend that the test dataset will have a similiar distribution of sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mean of survival according to sex\n",
    "train[['Sex', 'Survived']].groupby('Sex', as_index = False).mean().sort_values(by = 'Survived', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualisation for the probability of survival according to sex\n",
    "sns.barplot(x = 'Sex', y ='Survived', data = train)\n",
    "plt.ylabel('Probability of survival')\n",
    "plt.title('Survival Probability by Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font> Female passengers are more likely to survive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1.2.Categorical variable: Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts of the Pclass column in the training dataset\n",
    "\n",
    "train['Pclass'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of survival by passenger class in the training dataset\n",
    "\n",
    "train[['Pclass', 'Survived']].groupby(['Pclass'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Pclass distributions for survived and not survived\n",
    " \n",
    "ax=sns.kdeplot(train.loc[(train['Survived'] == 0),'Pclass'],shade=True,color='r',label='Not Survived')\n",
    "ax.legend()\n",
    "ax=sns.kdeplot(train.loc[(train['Survived'] == 1),'Pclass'],shade=True,color='b',label='Survived')\n",
    "ax.legend()\n",
    "\n",
    "plt.title(\"Passenger Class Distribution - Survived vs Non-Survived\", fontsize = 25)\n",
    "labels = ['First', 'Second', 'Third']\n",
    "plt.xticks(sorted(train.Pclass.unique()),labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Pclass', y ='Survived', data = train)\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Survival Probability by Passenger Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font> The probability of survival decreases with a decrease in passenger class. It can therefore be assumed that first class passengers were prioritised during the evacuation. Evidently, from the two graphs above, Pclass plays an important role in determining whether a passenger did or did not survive. According to the training dataset, 63% of the 1st class passengers survived, 48% of the 2nd class passengers survived and only 24% of the 3rd class passengers survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1.3.Categorical variables combined: Sex and Plass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Survival by gender and passenger class\n",
    "sns.factorplot(x = 'Pclass', y = 'Survived', hue = 'Sex', data = train, kind = 'bar').despine(left = True)\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Survival Probability by Sex and Passenger Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font>The graph above indicates that in every class, females where always more likely to survive. It can also be seen that males in the first class were more likely to survive than in any other class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1.4.Categorical variable: Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Value counts of the Embarked column \n",
    "#NAN is the missing values in Embarked\n",
    "train['Embarked'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of survival by point of embarkation\n",
    "train[['Embarked', 'Survived']].groupby(['Embarked'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation for the probability of survival according to point of embarkation\n",
    "sns.barplot(x = 'Embarked', y ='Survived', data = train)\n",
    "plt.ylabel('Probability of Survival')\n",
    "plt.title('Survival Probability by Point of Embarkation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font> The probability of survival is highest for location C and lowest for location S.\n",
    "Perhaps first class passengers embarked from location C and therefore because first class passengers had a higher chance of survival, location c also has the highest chance of survival. As an alternative perhaps third class passengers embarked from location S and because third class passengers had the lowest chance of survival , location S also has the lowest survival probability. This hypothesis is tested in section 4.2.1.5 below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1.5.Categorical variable combined: Embarked and Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualisation for the relationship between class and embark \n",
    "sns.factorplot('Pclass', col = 'Embarked', data = train, kind = 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font> The hypothesis discussed in section 4.1.2.4 appears to be correct.  Location S has majority of the third class passengers and the majority of passengers embarking from location C are first class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gia\n",
    "In this dataset, the numerical variables are:\n",
    "1) SibSp\n",
    "2) Parch\n",
    "3) Age\n",
    "4) Fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2.1.Numerical variables correlation with survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap of numerical variables\n",
    "df_num = train[['Survived','Age','SibSp','Parch','Fare']]\n",
    "sns.heatmap(df_num.corr(), annot=True,cmap=\"RdBu\")\n",
    "plt.title(\"Correlations Among Numeric Features\", fontsize = 18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font> The heatmap displayed above shows that Parch and SiSp often travel together.Therefore it will useful to create a byThemselves and a family size feature.\n",
    "we also see that Fare has a pretty large positive correlation to survival, thus it may be an important metric in training the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2.2.Numerical variable: SibSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts of the SibSp column \n",
    "train['SibSp'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of survival by SibSp\n",
    "train[['SibSp', 'Survived']].groupby('SibSp', as_index = False).mean().sort_values(by = 'Survived', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation for probability of survival according to SiSP \n",
    "sns.barplot(x = 'SibSp', y ='Survived', data = train)\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Survival Probability by SibSp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2.3.Numerical variable: Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts of the Parch column \n",
    "train['Parch'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of survival by Parch\n",
    "train[['Parch', 'Survived']].groupby('Parch', as_index = False).mean().sort_values(by = 'Survived', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation for probability of survival according to Parch\n",
    "sns.barplot(x = 'Parch', y ='Survived', data = train)\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Survival Probability by Parch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2.4.Numerical variable: Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passenger age distribution\n",
    "sns.distplot(train['Age'], label = 'Skewness: %.2f'%(train['Age'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Passenger Age Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution by survival\n",
    "sns.FacetGrid(train, col = 'Survived').map(sns.distplot, 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(train['Age'][train['Survived'] == 0], label = 'Did not survive')\n",
    "sns.kdeplot(train['Age'][train['Survived'] == 1], label = 'Survived')\n",
    "plt.xlabel('Age')\n",
    "plt.legend()\n",
    "plt.title('Passenger Age Distribution by Survival')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(train['Age'], label = 'All passengers')\n",
    "sns.kdeplot(train['Age'][train['Survived'] == 1], label = 'Survived')\n",
    "plt.xlabel('Age')\n",
    "plt.legend()\n",
    "plt.title('Passenger Age Distribution by Survival')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2.5.Numerical variable: Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passenger fare distribution\n",
    "sns.distplot(train['Fare'], label = 'Skewness: %.2f'%(train['Fare'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.ylabel('Passenger Fare Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font> The majority of passengers paid low fares where there are few people who paid very large fares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(train, col = 'Survived').map(sns.distplot, 'Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(train['Fare'][train['Survived'] == 0], label = 'Did not survive')\n",
    "sns.kdeplot(train['Fare'][train['Survived'] == 1], label = 'Survived')\n",
    "plt.xlabel('Fare')\n",
    "plt.legend()\n",
    "plt.title('Passenger Fare Distribution by Survival')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Correlation between categorical and numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3.1.All variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train[['Survived', 'SibSp', 'Parch', 'Age', 'Fare','Pclass']].corr(), annot = True, fmt = '.2f', cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font>  Fare appears to have a high correlation with survival and Pclass has a high ngeative correlation with survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data preprocessing\n",
    "\n",
    "Now that we know what features are correlated and some other important factors, we can get the dataset into a form to be modelled and trained. This includes:\n",
    "- Data transformation \n",
    "- Dealing with ouliers\n",
    "- Drop and fill missing values\n",
    "- Feature engineering\n",
    "- Feature encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Data transformation\n",
    "\n",
    "Apply a log transformation to fair as it has a high right-skewnewss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Fare distribution before transformation\n",
    "sns.distplot(train['Fare'], label = 'Skewness: %.2f'%(train['Fare'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Passenger Fare Distribution before transformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to reduce skewness in fare, apply log transformation \n",
    "# In order to not lose the single missing value , we fill it now with the median fare \n",
    "# Fill missing value for Fare \n",
    "\n",
    "median = test['Fare'].dropna().median()\n",
    "test['Fare'].fillna(median, inplace = True)\n",
    "\n",
    "train['Fare'] = train['Fare'].map(lambda x: np.log(x) if x > 0 else 0)\n",
    "test['Fare'] = test['Fare'].map(lambda x: np.log(x) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After log transformation\n",
    "\n",
    "sns.distplot(train['Fare'], label = 'Skewness: %.2f'%(train['Fare'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Fare Distribution After Log Transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Remove Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are points in the dataset that don't conform with majority of the data (they are extreme values). Outliers need to be addressed as they tend to skew data and can cause inaccurate model predictions. The Tukey method is used to detect these outliers. Outliers can only be determined for numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers \n",
    "def detect_outliers(df, n, features):\n",
    "    \"\"\"\"\n",
    "    This function loops through the list of features and detects outliers in each feature. A data point is considered to be \n",
    "    an outlier if it is less than Q1-1.5*IQR or if it is greater than Q3+1.5*IQR. Once the outliers have been determined for \n",
    "    a feature, their indices will be stored in a list and then the loop will proceed to the next feature. This process repeats\n",
    "    until the last feature is complete. Finally, using the list with the indices of the outliers, the frequency of outliers is\n",
    "    determined and if the frequency is greater than n then the list fill be returned.    \n",
    "    \"\"\"\n",
    "    outlierIndices = [] \n",
    "    for col in features: \n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        Q3 = np.percentile(df[col], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        outlierStep = 1.5 * IQR \n",
    "        outlierList = df[(df[col] < Q1 - outlierStep) | (df[col] > Q3 + outlierStep)].index\n",
    "        outlierIndices.extend(outlierList) \n",
    "    outlierIndices = Counter(outlierIndices)\n",
    "    multipleOutliers = list(key for key, value in outlierIndices.items() if value > n) \n",
    "    return multipleOutliers\n",
    "outliers_to_drop_test = detect_outliers(test, 2, ['Age', 'SibSp', 'Parch', 'Fare'])\n",
    "outliers_to_drop = detect_outliers(train, 2, ['Age', 'SibSp', 'Parch', 'Fare'])\n",
    "print(\"The indices where outliers occur are {}: \".format(len(outliers_to_drop)), outliers_to_drop) \n",
    "print(\"Train Set Before: {} rows\".format(len(train)))\n",
    "train = train.drop(outliers_to_drop, axis = 0).reset_index(drop = True)\n",
    "print(\"Train Set After: {} rows\".format(len(train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers in numerical variables\n",
    "# Visualise the 10 rows identified above as rows containing outliers\n",
    "\n",
    "train.loc[outliers_to_drop, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Drop and fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ticket and cabin features from training and test set as they are unique or missing many values\n",
    "\n",
    "train = train.drop(['Ticket', 'Cabin'], axis = 1)\n",
    "test = test.drop(['Ticket', 'Cabin'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill missing value in Embarked with mode as only 3 values\n",
    "\n",
    "mode = train['Embarked'].dropna().mode()[0]\n",
    "train['Embarked'].fillna(mode, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check where indeces of missing ages are\n",
    "\n",
    "age_nan_indices_train = list(train[train['Age'].isnull()].index)\n",
    "len(age_nan_indices_train)\n",
    "age_nan_indices_test = list(test[test['Age'].isnull()].index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age is correlated correlated with SibSp, Parch and Pclass as shown in section 4. Loop through each of the rows which have the same corresponding values and fill the missing age with their median. Otherwise fill with the Age median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_age = train['Age'].median()\n",
    "\n",
    "for index in age_nan_indices_train:\n",
    "    predict_age = train['Age'][(train['SibSp'] == train.iloc[index]['SibSp']) \n",
    "                                 & (train['Parch'] == train.iloc[index]['Parch'])\n",
    "                                 & (train['Pclass'] == train.iloc[index][\"Pclass\"])].median()\n",
    "    if np.isnan(predict_age):\n",
    "        train['Age'].iloc[index] = median_age\n",
    "    else:\n",
    "        train['Age'].iloc[index] = predict_age\n",
    "combine = pd.concat([train, test], axis = 0).reset_index(drop = True)\n",
    "median_age = combine['Age'].median()\n",
    "for index in age_nan_indices_test:\n",
    "    # use larger sample to fill test data \n",
    "    test['Age'].iloc[index] = median_age  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure there are no more missing ages \n",
    "\n",
    "print(train['Age'].isnull().sum())\n",
    "test['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Feature engineering\n",
    "\n",
    "We create new features from existing features to obtain an improved model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title from name column\n",
    "\n",
    "train['Title'] = [name.split(',')[1].split('.')[0].strip() for name in train['Name']]\n",
    "train[['Name', 'Title']].head()\n",
    "test['Title'] = [name.split(',')[1].split('.')[0].strip() for name in test['Name']]\n",
    "test[['Name', 'Title']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts of Title\n",
    "train['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the testing titles\n",
    "\n",
    "test['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplify Title as there are several unique titles that do not necessarily have a trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'] = train['Title'].replace(['Dr', 'Rev', 'Col', 'Major', 'Lady', 'Jonkheer', 'Don', 'Capt', 'the Countess',\n",
    "                                             'Sir'], 'Rare')\n",
    "train['Title'] = train['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "train['Title'] = train['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "test['Title'] = test['Title'].replace(['Dr', 'Rev', 'Col',  'Capt', 'Dona'], 'Rare')\n",
    "test['Title'] = test['Title'].replace(['Ms'], 'Miss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the name column as title has been extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('Name', axis = 1)\n",
    "train.head()\n",
    "\n",
    "test = test.drop('Name', axis = 1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Title', 'Survived']].groupby(['Title'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font> Woman and young males had a high chance of survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 byThemselves\n",
    "\n",
    "Simplify and summarize data to show if passenegers were alone, as opposed to information about both siblings and parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "train[['SibSp', 'Parch', 'FamilySize']].head()\n",
    "\n",
    "test['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n",
    "test[['SibSp', 'Parch', 'FamilySize']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create byThemselves feature as familySize may have more information than we need, leading to overfitting\n",
    "\n",
    "train['byThemselves'] = 0\n",
    "train.loc[train['FamilySize'] == 1, 'byThemselves'] = 1\n",
    "\n",
    "test['byThemselves'] = 0\n",
    "test.loc[test['FamilySize'] == 1, 'byThemselves'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop SibSp, Parch and FamilySize as this is contained in byThemselves\n",
    "\n",
    "train = train.drop(['SibSp', 'Parch','FamilySize'], axis = 1)\n",
    "test = test.drop(['SibSp', 'Parch','FamilySize'], axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.3 Age*Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First convert Age into an ordinal variable. Group Ages into 4 age bands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['AgeBand'] = pd.cut(train['Age'], 4)\n",
    "test['AgeBand'] = pd.cut(test['Age'], 4)\n",
    "print(train['AgeBand'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Age'] <= 20.315, 'Age'] = 0\n",
    "train.loc[(train['Age'] > 20.315) & (train['Age'] <= 40.21), 'Age'] = 1\n",
    "train.loc[(train['Age'] > 40.21) & (train['Age'] <= 60.105), 'Age'] = 2\n",
    "train.loc[train['Age'] > 60.105,'Age'] = 3\n",
    "\n",
    "test.loc[test['Age'] <= 20.315, 'Age'] = 0\n",
    "test.loc[(test['Age'] > 20.315) & (test['Age'] <= 40.21), 'Age'] = 1\n",
    "test.loc[(test['Age'] > 40.21) & (test['Age'] <= 60.105), 'Age'] = 2\n",
    "test.loc[test['Age'] > 60.105,'Age'] = 3\n",
    "\n",
    "# Drop age band feature\n",
    "train = train.drop('AgeBand', axis = 1)\n",
    "test = test.drop('AgeBand', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert ordinal Age into integer\n",
    "\n",
    "train['Age'] = train['Age'].astype('int')\n",
    "test['Age'] = test['Age'].astype('int')\n",
    "train['Age'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Age*Class\n",
    "\n",
    "train['Age*Class'] = train['Age'] * train['Pclass']\n",
    "test['Age*Class'] = test['Age'] * test['Pclass']\n",
    "train[['Age', 'Pclass', 'Age*Class']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin Fare \n",
    "train['FareBand'] = pd.qcut(train['Fare'], 4)\n",
    "test['FareBand'] = pd.qcut(test['Fare'], 4)\n",
    "train['FareBand'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encoding, simliar to age\n",
    "\n",
    "train.loc[train['Fare'] <= 2.066, 'Fare'] = 0\n",
    "train.loc[(train['Fare'] > 2.066) & (train['Fare'] <= 2.671), 'Fare'] = 1\n",
    "train.loc[(train['Fare'] > 2.671) & (train['Fare'] <= 3.418), 'Fare'] = 2\n",
    "train.loc[train['Fare'] > 3.418, 'Fare'] = 3\n",
    "\n",
    "test.loc[test['Fare'] <= 2.066, 'Fare'] = 0\n",
    "test.loc[(test['Fare'] > 2.066) & (test['Fare'] <= 2.671), 'Fare'] = 1\n",
    "test.loc[(test['Fare'] > 2.671) & (test['Fare'] <= 3.418), 'Fare'] = 2\n",
    "test.loc[test['Fare'] > 3.418, 'Fare'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['FareBand'], axis = 1)\n",
    "test = test.drop(['FareBand'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Fare into integer\n",
    "\n",
    "train['Fare'] = train['Fare'].astype('int')\n",
    "test['Fare'] = test['Fare'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Feature encoding \n",
    "\n",
    "Variables must be numeric to use for machine learning. Age and Fare were done when Binning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label = LabelEncoder() \n",
    "train['Embarked'] = label.fit_transform(train['Embarked'])\n",
    "test['Embarked'] = label.fit_transform(test['Embarked'])\n",
    "train['Title'] = label.fit_transform(train['Title'])\n",
    "test['Title'] = label.fit_transform(test['Title'])\n",
    "train['Sex'] = train['Sex'].map({'male': 0, 'female': 1})\n",
    "test['Sex'] = test['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.drop('PassengerId', axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Survived'] = train['Survived'].astype('int')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train[['Survived', 'Pclass', 'Sex', 'Age', 'Fare','Embarked','Title','byThemselves','Age*Class']].corr(), annot = True, fmt = '.2f', cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After data preprocessing, we can see how all of the new and remaining features are correlated in the figure above. Clearly sex has the greatest correlation with survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modelling\n",
    "\n",
    "For the modelling part of this project we will utilise the Scikit-learn library for machine learning. \n",
    "\n",
    " As discussed above, this is a classfication problem, so consequently will use classfication models for our training.  We have chosen to investigate the performance of the following classifiers:\n",
    "\n",
    "- Logistic regression\n",
    "- Multi Layer Perceptron\n",
    "- K-nearest neighbours\n",
    "- Gaussian naive bayes\n",
    "- Linear SVC\n",
    "- Stochastic gradient descent\n",
    "- Random forest\n",
    "- Support vector machines\n",
    "\n",
    "In this section , we will fit the models to the training data set and evaluate the models' prediction accuracy. Further on we  will implement feature tuning and hyperparameter tuning to further boost the performance of the the following models:\n",
    "\n",
    "- Logistic regression\n",
    "- Multi Layer Perceptron\n",
    "- K-nearest neighbours\n",
    "- Random Forest \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('Survived', axis = 1)\n",
    "Y_train = train['Survived']\n",
    "X_test = test.drop('PassengerId', axis = 1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Training Accuracy before any tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "KNNtrained=knn.fit(X_train, Y_train)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "\n",
    "#Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "LGtrained=logreg.fit(X_train, Y_train)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "\n",
    "#Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "\n",
    "#MLP\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, Y_train)\n",
    "acc_mlp = round(mlp.score(X_train, Y_train) * 100, 2)\n",
    "\n",
    "#SGD\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "\n",
    "#SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
    "\n",
    "#Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators = 100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "\n",
    "models = pd.DataFrame({'Model': ['KNN', 'Logistic Regression','Naive Bayes','MLP','Stochastic Gradient Decent','Random Forest'],\n",
    "                       'Score': [ acc_knn, acc_log,  acc_gaussian,acc_mlp,\n",
    "                                 acc_sgd, acc_random_forest ]})\n",
    "\n",
    "models.sort_values(by = 'Score', ascending = False, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our models have seemingly impressive training accuracy. Although  high scores could indicate that our algorithms are likely to perform well on unseen datasets, it  could also indicate over fitting which will result in poor performance  on the test set. Therefore we should focus on our models' ability to accurately predict  outcomes from data they have not seen before. This lead us to our next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 K-fold cross validation\n",
    "\n",
    "K-fold cross validation is a method that iteratively sets aside a subset of data for validation purposes. The rest of the data is used for training purposes. The validation data set is unseen to the training model. Therefore it provides a fair estimation of the results we might expect to see from the real test set submitted to Kaggle.\n",
    "\n",
    "We compute the accuracy and cross-entropy log-loss for each algorithm to determine its performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list which contains classifiers \n",
    "classifiers = [ MLPClassifier(),\n",
    "                LogisticRegression(), \n",
    "                GaussianNB(),\n",
    "                KNeighborsClassifier(n_neighbors = 5),   \n",
    "                SGDClassifier(), \n",
    "                LinearSVC(),\n",
    "                RandomForestClassifier(),\n",
    "               ]\n",
    "\n",
    "if len(classifiers) is not 7: \n",
    "    print(\"error\")\n",
    "\n",
    "cross_val_results = []\n",
    "cross_val_losses = []\n",
    "\n",
    "for classifier in classifiers:\n",
    "    cross_val_results.append(cross_val_score(classifier, X_train, Y_train, scoring = 'accuracy', cv = 5))\n",
    "    cross_val_losses.append(cross_val_score(classifier, X_train, Y_train, scoring = 'neg_log_loss', cv = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neg_log_loss provides the Cross Entropy loss which is a good identifier for errors in training algorithms for both classification and regression models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and standard deviation of cross validation results for each classifier  \n",
    "\n",
    "cross_val_mean = []\n",
    "cross_val_std = []\n",
    "cross_val_loss_mean =[]\n",
    "cross_val_loss_std = []\n",
    "\n",
    "for cross_val_result in cross_val_results:\n",
    "    cross_val_mean.append(cross_val_result.mean())\n",
    "    cross_val_std.append(cross_val_result.std())\n",
    "\n",
    "for cross_val_loss in cross_val_losses:\n",
    "    cross_val_loss_mean.append(cross_val_loss.mean())\n",
    "    cross_val_loss_std.append(cross_val_loss.std())    \n",
    "\n",
    "\n",
    "#putting our cross val mean and standard deviation for each algorithm into a data frame\n",
    "cross_val_res = pd.DataFrame({'Cross Validation Mean': cross_val_mean, 'Cross Validation Std': cross_val_std, 'Algorithm': [ 'Multilayer perceptron','Logistic Regression','Naive Bayes', 'K Nearest Neighbours', 'Stochastic Gradient Decent', 'Linear SVC', 'Random Forest']})\n",
    "cross_val_los = pd.DataFrame({'Cross Validation Mean': cross_val_loss_mean, 'Cross Validation Std': cross_val_loss_std, 'Algorithm': [ 'Multilayer perceptron','Logistic Regression','Naive Bayes', 'K Nearest Neighbours',  'Stochastic Gradient Decent', 'Linear SVC', 'Random Forest']})\n",
    "print('Table Showing Cross Validation Mean Accuracy')\n",
    "print(cross_val_res.sort_values(by = 'Cross Validation Mean', ascending = False, ignore_index = True))\n",
    "print('\\nTable Showing Cross Validation Mean Loss')\n",
    "print(cross_val_los.sort_values(by = 'Cross Validation Mean', ascending = True, ignore_index = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>Observation:</font> Random Forest has the greatest accuracy followed by MLP. However, MLP has the least observable loss and would appear to be the 'best' at first glance. \n",
    "\n",
    "Nonetheless, 4 algorithms will be tuned below and the scores observed once more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('Cross Validation Mean', 'Algorithm', data = cross_val_res, order = cross_val_res.sort_values(by = 'Cross Validation Mean', ascending = False)['Algorithm'], palette = 'Set3', **{'xerr': cross_val_std})\n",
    "plt.ylabel('Algorithm')\n",
    "plt.title('Cross Validation Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('Cross Validation Mean', 'Algorithm', data = cross_val_los, order = cross_val_los.sort_values(by = 'Cross Validation Mean', ascending = False)['Algorithm'], palette = 'Set3', **{'xerr': cross_val_loss_std})\n",
    "plt.ylabel('Algorithm')\n",
    "plt.title('Cross Validation Losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Feature Tuning\n",
    "\n",
    "The best remaining features can be found for each algorithm and the rest can be dropped for each respective algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of correct classifications (survived or did not survive) is proportional to the \"accuracy\" scoring\n",
    "RFECV1 = RFECV(estimator=LogisticRegression(), step=1, cv=5, scoring='accuracy')\n",
    "RFECV1.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Optimal number of features: %d\" % RFECV1.n_features_)\n",
    "print('Selected features: %s' % list(X_train.columns[RFECV1.support_]))\n",
    "\n",
    "# Plot the number of features VS. the CV scores\n",
    "plt.xlabel(\"Number of features that are selected\")\n",
    "plt.ylabel(\"Cross validation score \")\n",
    "plt.plot(range(1, len(RFECV1.grid_scores_) + 1), RFECV1.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No variables need to be dropped as 8 is the optimal number for Logistic regression\n",
    "X_train_LR=X_train\n",
    "X_test_LR=X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFECV2 = RFECV(estimator=RandomForestClassifier(), step=1, cv=5, scoring='accuracy')\n",
    "RFECV2.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Optimal number of features: %d\" % RFECV2.n_features_)\n",
    "print('Selected features: %s' % list(X_train.columns[RFECV2.support_]))\n",
    "\n",
    "# Plot the number of features VS. the CV scores\n",
    "plt.xlabel(\"Number of features that are selected\")\n",
    "plt.ylabel(\"Cross validation score \")\n",
    "plt.plot(range(1, len(RFECV2.grid_scores_) + 1), RFECV2.grid_scores_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the above, for Random Forest we should drop 3 columns\n",
    "X_train_RF = X_train.drop(['Age'], axis =1).copy()\n",
    "X_test_RF = X_test.drop(['Age'], axis =1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the Best important features according to Logistic Regression\n",
    "sfs_selector = SequentialFeatureSelector(estimator=KNeighborsClassifier(), n_features_to_select = 6, cv =10, direction ='backward')\n",
    "sfs_selector.fit(X_train, Y_train)\n",
    "X_train.columns[sfs_selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the above, for KNN we  drop Age*class, and title columns\n",
    "X_train_KNN = X_train.drop(['Age*Class', 'Title'], axis =1).copy()\n",
    "X_test_KNN = X_test.drop(['Age*Class', 'Title'], axis =1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the back-propagation of the MLP function the weights of the features are constantly being updated until a final solution is reached.Thus, feature importance cannot be predetermined. As such all features are used when training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Hyperparameter Tuning\n",
    "Hyperparameter tuning is the process of tuning the parameters of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2.1 Hyperparameter tuning for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=50)\n",
    "param_grid = {'alpha': [1,1e-3,1e-5],  \n",
    "              'hidden_layer_sizes': [(50,50,50),(3,), (50,190,3), (64,64,64) ],\n",
    "              'activation': ['tanh','relu','logistic'],  \n",
    "              'solver': ['sgd','adam'],\n",
    "              'learning_rate': ['constant','adaptive']\n",
    "}\n",
    "grid = GridSearchCV(mlp, param_grid,n_jobs=-1, cv=5) \n",
    "grid.fit(X_train, Y_train)\n",
    "MLP_tuned= grid.best_estimator_\n",
    "MLP_trained_tuned=MLP_tuned.fit(X_train, Y_train)\n",
    "print(\"Best parameters: \", grid.best_params_) \n",
    "Y_pred = MLP_trained_tuned.predict(X_test)\n",
    "submit = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': Y_pred})\n",
    "submit.to_csv(\"submissionMLP.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The multilayer perceptron(MLP) is an Artificial neural network with one or more  hidden layers. The MLP has the advantage over the Perceptron algorithm in that it is able to handle non linear mapping of inputs to outputs. The MLP is a feedforward algorithm that performs a weighted summation of the inputs and their respective weights. This summation is then fed into a activation function such as ReLU to determine the output. The output of each of this nodes is then fed into the next hidden layers and then to the output. The MLP also has back propagation which allows it to iteratively adjust the weights in the network to reduce the cost function. The MLP was chosen for hyperparameter tuning as it has one of the highest accuracy scores and one of the lowest standard deviations (Bento, 2021).\n",
    "\n",
    "\n",
    "Using the GridSearchCV method with the following parameters: the classifier, a grid of hyperparameters and a K-fold cross validation value. The parameter grid includes the alpha value used for regularization(which reduces overfitting), values for how many nodes in each of the 3 hidden layers , the activation function , the solver used for backpropagation and the learning rate. The gridSearchCV then finds the parameters which result in the highest accurcay (1.17. Neural network models (supervised), n.d.).\n",
    "\n",
    "Bento, C., 2021. Multilayer Perceptron Explained with a Real-Life Example and Python Code: Sentiment Analysis. [online] Medium. Available at: <https://towardsdatascience.com/multilayer-perceptron-explained-with-a-real-life-example-and-python-code-sentiment-analysis-cb408ee93141> [Accessed 14 June 2022].\n",
    "\n",
    "scikit-learn. n.d. 1.17. Neural network models (supervised). [online] Available at: <https://scikit-learn.org/stable/modules/neural_networks_supervised.html> [Accessed 14 June 2022].\n",
    "\n",
    "(Aiden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2.2 Hyperparameter tuning for KNN\n",
    "\n",
    "In this section, we analyse how the number of nearest neighbors, the leaf size and choice of distance metric affect the performance of the KNN  classifier. Ultimately, we find the optimal combination  from a specified list of parameters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we are focusing on the optimal value for K - the number of nearest neighbors considered in the vote when classifying the point of interest.  The graph below highlights the bias variance tradeoff that occurs as K increases. However the optimal K value is dependent on the other hyper parameters that are settled on. Consequently the KNN model is retrained 2 cells below, taking into consideration how all 3 hyper-parameters affect the model when they are acting together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = list(range(1,50))\n",
    "hyperparameters = dict(n_neighbors=n_neighbors)\n",
    "grid = GridSearchCV(KNeighborsClassifier(), hyperparameters, cv=5,n_jobs=-1,return_train_score= True )\n",
    "grid.fit(X_train, Y_train)\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "plt.plot(results['param_n_neighbors'],results['mean_test_score'],color='orange',markerfacecolor='orange', markersize=10,label='mean CV score with CV=5')\n",
    "plt.plot(results['param_n_neighbors'],results['mean_train_score'],color='blue',markerfacecolor='blue', markersize=10,label='mean training score')\n",
    "plt.title('Score vs K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"best parameter:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we are focusing on the optimal value for leaf size.  However the optimal value is dependent on the other hyper parameters that are settled on. Consequently the KNN model is retrained 1 cells below, taking into consideration how all 3 hyper-parameters affect the model when they are acting together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_size = list(range(1,30))\n",
    "hyperparameters = dict(leaf_size=leaf_size)\n",
    "grid = GridSearchCV(KNeighborsClassifier(), hyperparameters, cv=5,n_jobs=-1,return_train_score= True )\n",
    "grid.fit(X_train, Y_train)\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "plt.plot(results['param_leaf_size'],results['mean_test_score'],color='orange',markerfacecolor='orange', markersize=10,label='mean CV score with CV=5')\n",
    "plt.plot(results['param_leaf_size'],results['mean_train_score'],color='blue',markerfacecolor='blue', markersize=10,label='mean training score')\n",
    "plt.title('Score vs Leaf  Size')\n",
    "plt.xlabel('Leaf Size')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"best parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we use gridSearchCV to determine the optimal combination of hyper-parameters within specified ranges. As can be seen in the \"results after tuning' section, there is a significant improvement in the cross validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_size = list(range(1,100))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "grid = GridSearchCV(KNeighborsClassifier(), hyperparameters, cv=5,n_jobs=-1, )\n",
    "grid.fit(X_train, Y_train)\n",
    "KNN_tuned = grid.best_estimator_\n",
    "KNN_trained_tuned=KNN_tuned.fit(X_train, Y_train)\n",
    "survival_predications2=KNN_trained_tuned.predict(X_test)\n",
    "print(\"Best parameters: \", grid.best_params_) \n",
    "Y_pred = KNN_trained_tuned.predict(X_test)\n",
    "submit = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': Y_pred})\n",
    "submit.to_csv(\"submissionKNN.csv\", index = False)\n",
    "results = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation K Nearest Neighbors is a non linear, nonparametric, supervised ML algorithm that is appropriate for both classification and regression problems (Guo et al.,,2003). KNN classifies data points by calculating the distances between vectors in multidimensional feature space (Guo et al.,,2003). The algorithm classifies an unlabeled data point by assigning it the most popular (most frequent) label of the k nearest points (Guo et al.,,2003).\n",
    "\n",
    "Guo, G., Wang, H., Bell, D., Bi, Y. and Greer, K., 2003, November. KNN model-based approach in classification. In OTM Confederated International Conferences\" On the Move to Meaningful Internet Systems\" (pp. 986-996). Springer, Berlin, Heidelberg.\n",
    "\n",
    "(Rael)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2.3 Hyperparameter tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 40, 60],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [  200, 1000,1600 ,1800, 2000]}\n",
    "\n",
    "#randomzed search to decrease time frame\n",
    "grid = RandomizedSearchCV(RandomForestClassifier(), param_grid, refit = True, n_iter = 25, cv = 5, verbose=3, n_jobs =-1)\n",
    "grid.fit(X_train_RF, Y_train)\n",
    "RF_tuned = grid.best_estimator_\n",
    "RF_trained_tuned = RF_tuned.fit(X_train_RF, Y_train) #using the feature tuning sets\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "Y_pred = RF_trained_tuned.predict(X_test_RF)\n",
    "submit = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': Y_pred})\n",
    "submit.to_csv(\"submissionRF.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest algorithm is considered a good classifying model( Dedja et al, 2022). It is a supervised machine learning algorithm. As it was one of the selected algorithms that produced one of the highest cross-validation accuracy scores and one of the lowest cross-validation loss scores, it was chosen to be tuned and retrained. The random forest machine learning algorithm takes the output of multiple decision trees and ‘democratically’ chooses the final outcome (Tibco, 2022). \n",
    "\n",
    "Decision trees themselves essentially ask true or false questions that lead to a final answer. In other words, each question (for example, ‘male’ or ‘female’?) is a node, and the outcome is a leaf node (Yiu, 2019). The idea is to have results of subgroups that are similar to one another but are different from the other groups (Yiu, 2019). The random forest works well because while some decision trees may be wrong, many others will be correct. Therefore, as a group, the decision trees can move in the right direction (Yiu, 2019). By using a concept known as ‘bagging,’ where each individual decision tree can randomly sample from the training dataset, with replacement, random forest will have different trees and therefore a low correlation between them (Yiu, 2019). The uncorrelated errors between the different trees means that they ‘protect each other’ from their individual errors. This generally results in a precise classifying algorithm overall. \n",
    "\n",
    "Using the RandomizedSearchCV method for time-efficiency, a grid of hyperparameters can be randomly sampled, with K-Fold cross-validation being performed with each combination of parameter values.  The hyperparameters that were searched through include: number of trees in the forest; number of data points per node before it must be split; minimum number of data points allowed in a leaf node; the maximum number of levels of each tree; and with or without replacement. Thereafter, the model is then retrained using the new-found ‘best’ hyperparameters\n",
    "\n",
    "\n",
    "Dedja,K., Pliakos,K., Vens,C., 2022. Explaining random forest prediction through diverse rulesets. \n",
    "\n",
    "TIBCO Software. 2022. What is a Random Forest?. [online] Available at: <https://www.tibco.com/reference-center/what-is-a-random-forest> [Accessed 14 June 2022].\n",
    "\n",
    "Yiu, T., 2019. Understanding Random Forest. [online] Medium. Available at: <https://towardsdatascience.com/understanding-random-forest-58381e0602d2> [Accessed 3 June 2022].\n",
    "\n",
    "(Ben)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2.4 Hyperparameter tuning for LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we are focusing on finding the optimal C value.  However the optimal value is dependent on the other hyper parameters that are settled on. Consequently the Logistic regression model is re-trained 1 cells below, taking into consideration how all 3 hyper-parameters affect the model when they are acting together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = [0.00001,0.0001,0.001,0.01,0.1,1,10,100]\n",
    "model = LogisticRegression()\n",
    "grid = dict(C=c_values)\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=5, scoring='accuracy',error_score=0, return_train_score= True)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, cv=5,return_train_score= True)\n",
    "LR_trained_tuned = grid_search.fit(X_train_LR, Y_train)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "plt.semilogx(results['param_C'],results['mean_test_score'],color='orange',markerfacecolor='orange', markersize=10,label='mean CV score with CV=5')\n",
    "plt.semilogx(results['param_C'],results['mean_train_score'],color='blue',markerfacecolor='blue', markersize=10,label='mean training score')\n",
    "plt.title('Score vs c Values')\n",
    "plt.xlabel('C value')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models and parameters\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear','sag','saga']\n",
    "penalty = ['none','l2','l1','elasticnet']\n",
    "c_values = [0.00001,0.0001,0.001,0.01,0.1,1,10,100]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=5, scoring='accuracy',error_score=0)\n",
    "\n",
    "LR_trained_tuned = grid_search.fit(X_train_LR, Y_train)\n",
    "LR_tuned = grid_search.best_estimator_\n",
    "# summarize results\n",
    "print(\"Best result of %f using %s\" % (LR_trained_tuned.best_score_, LR_trained_tuned.best_params_))\n",
    "means = LR_trained_tuned.cv_results_['mean_test_score']\n",
    "stds = LR_trained_tuned.cv_results_['std_test_score']\n",
    "params = LR_trained_tuned.cv_results_['params']\n",
    "Y_pred = LR_trained_tuned.predict(X_test_LR)\n",
    "submit = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': Y_pred})\n",
    "submit.to_csv(\"submissionLR.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: The Logistic Regression ML algorithm is a popular method used to classify binary data (Ekinci,Omurca,Acun,2018) and is thus useful for predicting whether passengers survived or did not survive. LR is based on an assumption that the dependent variable’s value is predicted by using the independent variables (Ekinci,Omurca,Acun,2018).Logistic regression operates in a similar way to linear regression however, logistic regression uses a binomial response variable. In the logistic regression model, Y is the dependent variable that we are trying to predict by observing the set of input (independent) variables X where X (xi,...,xk) (Ekinci,Omurca,Acun,2018). In this AI system, the values of Y are Y=0 for passengers that did not survive or Y=1 for passengers who did survive.The values of X are the features used to train the model. The conditional probability of this model follows a logistic distribution given by P(Y=1—X) (Ekinci,Omurca,Acun,2018). This is the regression function used to predict the survival outcome Y.\n",
    "\n",
    "\n",
    "Ekinci, E., Omurca, S.İ. and Acun, N., 2018. A comparative study on machine learning techniques using Titanic dataset. In 7th international conference on advanced technologies (pp. 411-416).\n",
    "\n",
    "(Gia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results after tuning:\n",
    "\n",
    "The results after tuning 4 of the models, as well as the original cross-validation scores for the models that were utilised but not tuned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_results = []\n",
    "cross_val_losses = []\n",
    "# Train using each model, finding accuracy and loss. :\n",
    "cross_val_results.append(cross_val_score(RF_tuned, X_train_RF, Y_train, scoring = 'accuracy', cv = 5))\n",
    "cross_val_losses.append(cross_val_score(RF_tuned, X_train_RF, Y_train, scoring = 'neg_log_loss', cv = 5))\n",
    "cross_val_results.append(cross_val_score(KNN_tuned, X_train, Y_train, scoring = 'accuracy', cv = 5))\n",
    "cross_val_losses.append(cross_val_score(KNN_tuned, X_train, Y_train, scoring = 'neg_log_loss', cv = 5))\n",
    "cross_val_results.append(cross_val_score(LR_tuned, X_train_LR, Y_train, scoring = 'accuracy', cv = 5))\n",
    "cross_val_losses.append(cross_val_score(LR_tuned, X_train_LR, Y_train, scoring = 'neg_log_loss', cv = 5))\n",
    "cross_val_results.append(cross_val_score(MLP_tuned, X_train, Y_train, scoring = 'accuracy', cv = 5))\n",
    "cross_val_losses.append(cross_val_score(MLP_tuned, X_train, Y_train, scoring = 'neg_log_loss', cv = 5))\n",
    "\n",
    "remaining_classifiers = [  \n",
    "                GaussianNB(),  \n",
    "                SGDClassifier(), \n",
    "                LinearSVC(),\n",
    "               ]\n",
    "\n",
    "\n",
    "for classifier in remaining_classifiers:\n",
    "    cross_val_results.append(cross_val_score(classifier, X_train, Y_train, scoring = 'accuracy', cv = 5))\n",
    "    cross_val_losses.append(cross_val_score(classifier, X_train, Y_train, scoring = 'neg_log_loss', cv = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and standard deviation of cross validation results for each classifier  \n",
    "\n",
    "cross_val_mean = []\n",
    "cross_val_std = []\n",
    "cross_val_loss_mean =[]\n",
    "cross_val_loss_std = []\n",
    "\n",
    "for cross_val_result in cross_val_results:\n",
    "    cross_val_mean.append(cross_val_result.mean())\n",
    "    cross_val_std.append(cross_val_result.std())\n",
    "\n",
    "for cross_val_loss in cross_val_losses:\n",
    "    cross_val_loss_mean.append(cross_val_loss.mean())\n",
    "    cross_val_loss_std.append(cross_val_loss.std())    \n",
    "\n",
    "    \n",
    "    \n",
    "#putting our cross val mean and standard deviation for each algorithm into a data frame\n",
    "cross_val_res = pd.DataFrame({'Cross Validation Mean': cross_val_mean, 'Cross Validation Std': cross_val_std, 'Algorithm': [ 'Random Forest', 'K Nearest Neighbours','Logistic Regression','Multilayer perceptron','Naive Bayes', 'Stochastic Gradient Decent', 'Linear SVC']})\n",
    "cross_val_los = pd.DataFrame({'Cross Validation Mean': cross_val_loss_mean, 'Cross Validation Std': cross_val_loss_std, 'Algorithm':  [ 'Random Forest', 'K Nearest Neighbours','Logistic Regression','Multilayer perceptron','Naive Bayes', 'Stochastic Gradient Decent', 'Linear SVC']})\n",
    "print('Table Showing Cross Validation Mean Accuracy')\n",
    "print(cross_val_res.sort_values(by = 'Cross Validation Mean', ascending = False, ignore_index = True))\n",
    "print('\\nTable Showing Cross Validation Mean Loss')\n",
    "print(cross_val_los.sort_values(by = 'Cross Validation Mean', ascending = True, ignore_index = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('Cross Validation Mean', 'Algorithm', data = cross_val_res, order = cross_val_res.sort_values(by = 'Cross Validation Mean', ascending = False)['Algorithm'], palette = 'Set3', **{'xerr': cross_val_std})\n",
    "plt.ylabel('Algorithm')\n",
    "plt.title('Cross Validation Scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation \n",
    "\n",
    "The tuned algorithms show improvement in accuracy as compared to before being tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Ensembles\n",
    "\n",
    "If cross-val scores were above 80 and the loss was above -2, assign a weighting of 2. Otherwise 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the other models now with no validation set to be used in the ensemble\n",
    "\n",
    "GNBtrained=GaussianNB().fit(X_train, Y_train)\n",
    "LSVCtrained=LinearSVC().fit(X_train, Y_train)\n",
    "SGDtrained=SGDClassifier().fit(X_train, Y_train)\n",
    "\n",
    "voting_classifier_hard = VotingClassifier(estimators = [('mlp',MLP_trained_tuned),('knn',KNN_trained_tuned),('lg',LR_trained_tuned),('rf',RF_trained_tuned)], voting = 'hard') \n",
    "voting_classifier_hard_trained=voting_classifier_hard.fit(X_train, Y_train)\n",
    "survival_predications=voting_classifier_hard_trained.predict(X_test)\n",
    "\n",
    "CV = cross_val_score(voting_classifier_hard,X_train,Y_train,cv=5)\n",
    "print('voting classifier cross validation score :',CV)\n",
    "print('voting classifier cross validation score mean :',CV.mean())\n",
    "print('voting classifier cross validation score standard deviation :',CV.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Preparing data for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our submission dataframe to have 418 rows and 2 columns, PassengerId and Survived. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "\n",
    "submit = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': survival_predications})\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataframe is ready for submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save csv file \n",
    "\n",
    "submit.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Possible ways to improve model accuracy\n",
    "\n",
    "- Analyse ticket and cabin features to determine if they have an unseen correlation with survival. \n",
    "- Try different machine learning models.\n",
    "- Determine if there are different features that can be engineered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Conclusion\n",
    "\n",
    "The final kaggle submissions are shown below. Data analysis and data processing were performed, including feature engineering and encoding. Initial training was done, followed by feature and hyperparameter tuning, after which K-Fold cross validation was done to determine accuracy of the models. Between the two stages, results improved. Ultimately, the success criteria are met. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](submissions.png)\n",
    "\n",
    "\n",
    "# ![](leaderboard.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Below are notebooks that inspired parts of the work done above. Other references for specific sections are in said sections. \n",
    "\n",
    "\n",
    "https://github.com/chongjason914/kaggle-titanic \n",
    "\n",
    "https://www.kaggle.com/code/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "\n",
    "https://github.com/murilogustineli/Titanic-Classification\n",
    "\n",
    "https://www.kaggle.com/code/kenjee/titanic-project-example/notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "The appendix contains graphs showing the learning curves, the validation and training losses, for each algorithm. It was not strictly necessary in the approach taken above, but nonetheless provides useful insight. \n",
    "\n",
    "Furthemore, the group and individual contributions are outlined here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Group Contributions: The group collaboratively did the data analysis,preprocessing and the remainder of the notebook, excluding the training and tuning of the Multi-Layer Perceptron, K-Nearest Neighbours, Logistic Regression and Random Forest. \n",
    "\n",
    "Individual Contributions:\n",
    "Aiden: Training and tuning of the Multi-Layer Perceptron.\n",
    "Benjamin: Training and tuning of the Random Forest classifier.\n",
    "Gia: Training and tuning of the Logistic Regression algorithm.\n",
    "Rael: Training and tuning of K-Nearest Neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Plot learning curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "        \n",
    "    x1 = np.linspace(0, 10, 8, endpoint=True) produces\n",
    "        8 evenly spaced points in the range 0 to 10\n",
    "    \"\"\"\n",
    "  \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "        \n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN - Learning Curve \n",
    "plot_learning_curve(estimator = KNN_trained_tuned,title = \"KNN -Learning Curve\",\n",
    "                    X = X_train, y = Y_train, cv = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian naive bayes - Learning Curve\n",
    "plot_learning_curve(estimator = GNBtrained,title = \"GNB -Learninc Curve\",\n",
    "                    X = X_train, y = Y_train, cv = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression - Learning Curve    \n",
    "plot_learning_curve(estimator = LR_trained_tuned ,title = \"Logistic Regression - Learning Curve\",\n",
    "                    X = X_train, y = Y_train, cv = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer Perceptron - Learning Curve    \n",
    "plot_learning_curve(estimator = MLP_trained_tuned ,title = \"MLP - Learning Curve\",\n",
    "                    X = X_train, y = Y_train, cv = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest - Learning Curve    gsLRM.best_estimator_\n",
    "plot_learning_curve(estimator = RF_trained_tuned ,title = \"Logistic Regression - Learning Curve\",\n",
    "                    X = X_train, y = Y_train, cv = 5);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c36ee19e8b3149dddcbe35ab5f92ddf427ca8ae53f8aa17469b1495a8f0d9a75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
