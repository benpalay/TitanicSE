{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.22.3.zip (11.5 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: numpy\n",
      "  Building wheel for numpy (PEP 517) ... \u001b[?25l|"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/Aiden/Documents/4th Year/ELEN4009-Software Engineering/Group Project/TitanicSE/draft2.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Aiden/Documents/4th%20Year/ELEN4009-Software%20Engineering/Group%20Project/TitanicSE/draft2.ipynb#ch0000001?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \u001b[39m# linear algebra\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Aiden/Documents/4th%20Year/ELEN4009-Software%20Engineering/Group%20Project/TitanicSE/draft2.ipynb#ch0000001?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \u001b[39m# data processing\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Aiden/Documents/4th%20Year/ELEN4009-Software%20Engineering/Group%20Project/TitanicSE/draft2.ipynb#ch0000001?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data to process it\n",
    "\n",
    "We import the training data and the test data, we will only be working with the training data. Ultimately, we will make the predictions about the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating the training and the testing data so we have more values to work with and therefor we can better approximate the missing values\n",
    "# the combined data differentiates the training set and the test set by encoding them with 1 and 0 respectively\n",
    "training = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "training['train_test'] = 1\n",
    "test['train_test'] = 0\n",
    "test['Survived'] = np.NaN\n",
    "all_data = pd.concat([training,test])\n",
    "\n",
    "%matplotlib inline\n",
    "all_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data analysis \n",
    "### 1.1 Visulisation and properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the null counts (missing data)\n",
    "training. info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data in training set\n",
    "\n",
    "missingno.matrix(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the central dendencies of the data\n",
    "training.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the numerical and the categorical data  so different visualisation techniques can be used\n",
    "\n",
    "df_numeric = training[['Age','SibSp','Parch','Fare']]\n",
    "df_catergorical = training[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the numerical values look at their distributions\n",
    "for i in df_numeric.columns:\n",
    "    plt.hist(df_numeric[i])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the correlations of the numerical data using a heat map\n",
    "\n",
    "sns.heatmap(df_numeric[['Fare','Parch','SibSp','Age']].corr(), annot = True, fmt = '.2f', cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DONNO WHAT THIS IS SHOWING US TRY UNDERSTAND\n",
    "# To get a feel for the survival rates we will compare the survival rate for Age, Fare, Parch and SibSp\n",
    "\n",
    "pd.pivot_table(training, index = 'Survived', values = ['Age','SibSp','Parch','Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make bar charts to understand the spread of the classes\n",
    "\n",
    "for i in df_catergorical.columns:\n",
    "    sns.barplot(df_catergorical[i].value_counts().index,df_catergorical[i].value_counts()).set_title(i);\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get a feel for the survival rates we will look at the survival rate for the categories in Pclass, Sex and Embarked\n",
    "\n",
    "print(pd.pivot_table(training, index = 'Survived', columns = 'Pclass', values = 'Ticket' ,aggfunc ='count'))\n",
    "print()\n",
    "print(pd.pivot_table(training, index = 'Survived', columns = 'Sex', values = 'Ticket' ,aggfunc ='count'))\n",
    "print()\n",
    "print(pd.pivot_table(training, index = 'Survived', columns = 'Embarked', values = 'Ticket' ,aggfunc ='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts of the sex column\n",
    "\n",
    "training['Sex'].value_counts(dropna = False)\n",
    "print('-'*40)\n",
    "# Comment: There are more male passengers than female passengers on titanic\n",
    "# Mean of survival by sex\n",
    "training[['Sex', 'Survived']].groupby('Sex', as_index = False).mean().sort_values(by = 'Survived', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Sex', y ='Survived', data = training)\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Survival Probability by Gender')\n",
    "\n",
    "# Comment: Female passengers are more likely to survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts of the Pclass column \n",
    "\n",
    "training['Pclass'].value_counts(dropna = False)\n",
    "print('-'*40)\n",
    "\n",
    "# Mean of survival by passenger class\n",
    "\n",
    "training[['Pclass', 'Survived']].groupby(['Pclass'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Pclass', y ='Survived', data = training)\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Survival Probability by Passenger Class')\n",
    "\n",
    "# Comment: Survival probability decrease with passenger class, first class passengers are prioritised during evacuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival by gender and passenger class\n",
    "\n",
    "g = sns.factorplot(x = 'Pclass', y = 'Survived', hue = 'Sex', data = training, kind = 'bar')\n",
    "g.despine(left = True)\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Survival Probability by Sex and Passenger Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts of the Embarked column \n",
    "\n",
    "training['Embarked'].value_counts(dropna = False)\n",
    "# Comment: Two missing values in the Embarked column\n",
    "print('-'*40)\n",
    "# Mean of survival by point of embarkation\n",
    "\n",
    "training[['Embarked', 'Survived']].groupby(['Embarked'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature engineering\n",
    "The data for the cabin and tickes has many classes and is very messy therefore we will try clean it up by leveraging these classes to create new variables that aren't in the training set, Furthermore we will look at if the persons title is related to that persons survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin data\n",
    "\n",
    "Determine if the cabin's letter had any impact on survival as well as determine if purchasing more thn one cabin had an impact on survivalDetermine if the cabin's letter had any impact on survival as well as determine if purchasing more thn one cabin had an impact on survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the value is 0 it means that the cabin number is missing\n",
    "# if the number is 1 it means that the passanger had one cain and if the number is 2 it means the passenger has 2 cabins ect\n",
    "df_catergorical.Cabin\n",
    "training['number_of_cabins'] = training.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\n",
    "print(training['number_of_cabins'].value_counts())\n",
    "\n",
    "\n",
    "pd.pivot_table(training, index = 'Survived', columns = 'number_of_cabins', values = 'Ticket' ,aggfunc ='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up the cabins into cabin letters and cabin letter to see if there is link to survival\n",
    "# n stands for null value meaining that there is a missing value or the cabin  does not have a letter\n",
    "training['cabin_letter'] = training.Cabin.apply(lambda x: str(x)[0])\n",
    "print(training.cabin_letter.value_counts())\n",
    "pd.pivot_table(training,index='Survived',columns='cabin_letter', values = 'Name', aggfunc='count')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ticket data\n",
    "looking at the numerical values on the ticket and the letters on the tickets and comparing them to survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at numeric vs non numeric tickecks\n",
    "training['numeric_ticket'] = training.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\n",
    "training['ticket_letters'] = training.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('/','').lower() if len(x.split(' ')[:-1]) >0 else 0)\n",
    "\n",
    "# 0 represents numeric numbers\n",
    "# 1 represents non numeric numbers\n",
    "\n",
    "training['numeric_ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the numeric and non numeric tickets to the survival rate\n",
    "# 0 represents numeric numbers\n",
    "# 1 represents non numeric numbers\n",
    "pd.pivot_table(training,index='Survived',columns='numeric_ticket', values = 'Ticket', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the different types of tickets basked on the ticket letters and compare them to the survival rateticket_letters\n",
    "# 0 means that the ticket does not have a letter \n",
    "pd.pivot_table(training,index='Survived',columns='ticket_letters', values = 'Ticket', aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.Name.head()\n",
    "# splits up the data into the persons title \n",
    "training['title'] = training.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "training['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping ages \n",
    "# bins = [0,16,21,26,31,36,41,46,51,56,61,66,71,76,81,86]\n",
    "# labels = ['0-15','16-20','21-25','26-30','31-35','36-40','41-45','46-50','51-55','56-60','61-65','71-75','76-80','81-85','86-x']\n",
    "# # labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "# train_copy['Age'] = pd.cut(train_copy['Age'], bins=bins, labels=labels, right=False)\n",
    "# train_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering \n",
    "training['FamilySize']=training['Parch']+training['SibSp']+1\n",
    "training=training.drop(['SibSp'],axis=1)\n",
    "training=training.drop(['Parch'],axis=1)\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts of the Family column \n",
    "\n",
    "training['FamilySize'].value_counts(dropna = False)\n",
    "print('-'*40)\n",
    "training[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plagiarised\n",
    "\n",
    "def detect_outliers(df, n, features):\n",
    "    \"\"\"\"\n",
    "    This function will loop through a list of features and detect outliers in each one of those features. In each\n",
    "    loop, a data point is deemed an outlier if it is less than the first quartile minus the outlier step or exceeds\n",
    "    third quartile plus the outlier step. The outlier step is defined as 1.5 times the interquartile range. Once the \n",
    "    outliers have been determined for one feature, their indices will be stored in a list before proceeding to the next\n",
    "    feature and the process repeats until the very last feature is completed. Finally, using the list with outlier \n",
    "    indices, we will count the frequencies of the index numbers and return them if their frequency exceeds n times.    \n",
    "    \"\"\"\n",
    "    outlier_indices = [] \n",
    "    for col in features: \n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        Q3 = np.percentile(df[col], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        outlier_step = 1.5 * IQR \n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step)].index\n",
    "        outlier_indices.extend(outlier_list_col) \n",
    "    outlier_indices = Counter(outlier_indices)\n",
    "    multiple_outliers = list(key for key, value in outlier_indices.items() if value > n) \n",
    "    return multiple_outliers\n",
    "\n",
    "# outliers_to_drop = detect_outliers(train_copy, 2, ['Age', 'SibSp', 'Parch', 'Fare'])\n",
    "# \n",
    "outliers_to_drop = detect_outliers(train_copy, 2, ['Age', 'FamilySize', 'Fare'])\n",
    "print(\"We will drop these {} indices: \".format(len(outliers_to_drop)), outliers_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "030fbe4849e2a3aea252fdb90aa6d847c8d88966b5e4ee449c89545a91296c3a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
